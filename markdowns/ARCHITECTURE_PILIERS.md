# ğŸ¯ ARCHITECTURE PROJET KIVENDTOUT - GRANDES CATÃ‰GORIES STRATÃ‰GIQUES

**Date** : 3 fÃ©vrier 2026  
**Client** : KiVendTout (E-commerce)  
**Objectif** : RÃ©pondre aux 11 exigences de la direction

---

## ğŸ“Š STRUCTURE DU PROJET EN 6 PILIERS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROJET KIVENDTOUT                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ PILIER 1â”‚          â”‚ PILIER 2â”‚          â”‚ PILIER 3â”‚
   â”‚ Stockageâ”‚          â”‚Streamingâ”‚          â”‚  Fraude â”‚
   â”‚  Fiable â”‚          â”‚Temps RÃ©elâ”‚         â”‚ Temps RÃ©elâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ PILIER 4â”‚          â”‚ PILIER 5â”‚          â”‚ PILIER 6â”‚
   â”‚Data Lakeâ”‚          â”‚Expositionâ”‚         â”‚    IA   â”‚
   â”‚Analyticsâ”‚          â”‚   API   â”‚          â”‚ConformitÃ©â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ›ï¸ PILIER 1 : FONDATIONS - STOCKAGE FIABLE & GOUVERNANCE

### ğŸ¯ Objectifs mÃ©tier

- **Exigence #1** : SystÃ¨me fiable pour donnÃ©es critiques avec intÃ©gritÃ© totale
- **Exigence #9** : ConformitÃ© sÃ©curitÃ© et protection donnÃ©es
- **Exigence #10** : AmÃ©liorer qualitÃ© des donnÃ©es

### ğŸ”§ Technologies

- **PostgreSQL 15** (OLTP transactionnel ACID)
- **dbt** (Data Build Tool - transformations + tests qualitÃ©)
- **Great Expectations** (validation donnÃ©es)

### ğŸ“‹ Livrables

1. **Base PostgreSQL complÃ¨te**
   - Schema normalisÃ© (3NF)
   - Tables : customers, products, orders, order_items, payments, sessions, fraud_alerts
   - Contraintes : PRIMARY KEY, FOREIGN KEY, CHECK, UNIQUE
   - Indexes optimisÃ©s (B-tree, Hash)
   - Triggers pour audit trail
2. **Gouvernance des donnÃ©es**

   - Dictionnaire de donnÃ©es
   - Lineage (traÃ§abilitÃ© origine â†’ destination)
   - Politique RGPD (anonymisation, droit Ã  l'oubli)
   - Chiffrement au repos (pgcrypto)
   - Backup automatique quotidien

3. **QualitÃ© des donnÃ©es**
   - Tests dbt (unicitÃ©, non-null, valeurs acceptables)
   - Monitoring anomalies (Great Expectations)
   - Reconciliation entre sources
   - Documentation auto-gÃ©nÃ©rÃ©e

### âœ… Statut actuel : **85% FAIT**

- âœ… PostgreSQL opÃ©rationnel (8 tables, 16k lignes)
- âœ… Contraintes FK + indexes
- â³ dbt Ã  installer (tests qualitÃ©)
- â³ Chiffrement + backup Ã  configurer

---

## âš¡ PILIER 2 : STREAMING - CAPTURE Ã‰VÃ‰NEMENTS TEMPS RÃ‰EL

### ğŸ¯ Objectifs mÃ©tier

- **Exigence #2** : Exploiter tous les Ã©vÃ©nements utilisateurs (clics, navigation, panier, paiements)
- **Exigence #7** : Garantir scalabilitÃ© face Ã  croissance trafic

### ğŸ”§ Technologies

- **Apache Kafka 3.6** (streaming distribuÃ©, 3 brokers HA)
- **MongoDB 7** (stockage flexible Ã©vÃ©nements)
- **Kafka Connect** (connecteurs sources/sinks)
- **Schema Registry** (versioning schemas Avro)

### ğŸ“‹ Livrables

1. **Pipeline ingestion Ã©vÃ©nements**
   - Topics Kafka : `user-events`, `payments`, `orders`, `cart-events`
   - Producteurs Python (site web, app mobile)
   - Replication factor = 3 (haute dispo)
   - Partitioning par customer_id (parallÃ©lisme)
2. **Stockage NoSQL Ã©vÃ©nements**

   - Collection MongoDB `events` (71k documents)
   - Indexes sur customer_id, session_id, event_type, timestamp
   - TTL automatique (rÃ©tention 2 ans)
   - AgrÃ©gations prÃ©-calculÃ©es (sessions/jour, produits vus)

3. **Architecture hautement disponible**
   - Kafka cluster 3 brokers (tolÃ©rance panne 1 nÅ“ud)
   - Zookeeper ensemble (coordination)
   - Consumer groups (load balancing)
   - Monitoring Kafka UI + JMX metrics

### âœ… Statut actuel : **25% FAIT**

- âœ… Kafka 3 brokers installÃ©s
- âœ… MongoDB installÃ©
- âœ… 71,694 events.jsonl prÃªts
- âŒ Topics pas crÃ©Ã©s
- âŒ Producers/Consumers pas codÃ©s
- âŒ Events pas dans MongoDB

### ğŸš€ DÃ©marrage (MVP streaming)

**Objectif** : valider un flux simple et mesurable (JSONL -> Kafka -> MongoDB).

**Plan MVP** :
1. CrÃ©er les topics Kafka `user-events`, `payments`, `orders`, `cart-events` avec 3 partitions et un facteur de rÃ©plication 3.
2. Produire les Ã©vÃ©nements depuis `kivendtout_dataset/events.jsonl` vers `user-events`.
3. Consommer `user-events` et insÃ©rer dans la collection MongoDB `events`.
4. Ajouter les index MongoDB et une rÃ©tention TTL de 2 ans.
5. Valider les volumes et la latence de bout en bout.

**Artefacts** :
1. `scripts/streaming/create_topics.sh`
2. `scripts/streaming/producer_events.py`
3. `scripts/streaming/consumer_events_to_mongo.py`
4. `markdowns/STREAMING_MVP.md` (mode opÃ©ratoire + mÃ©triques)

---

## ğŸš¨ PILIER 3 : SÃ‰CURITÃ‰ - DÃ‰TECTION FRAUDE TEMPS RÃ‰EL

### ğŸ¯ Objectifs mÃ©tier

- **Exigence #4** : Analyser Ã©vÃ©nements en temps rÃ©el pour identifier fraudes
- **Contrainte** : Augmentation fraudes aux paiements

### ğŸ”§ Technologies

- **Apache Flink 1.18** (stream processing CEP)
- **MLflow** (versioning modÃ¨les ML)
- **Scikit-learn / XGBoost** (modÃ¨les fraude)

### ğŸ“‹ Livrables

1. **RÃ¨gles de dÃ©tection temps rÃ©el (Flink)**

   ```
   RÃˆGLE 1 - High Amount    : montant > 100â‚¬ ET premier achat
   RÃˆGLE 2 - Country Mismatch: pays paiement â‰  pays client
   RÃˆGLE 3 - Velocity        : >5 tentatives en 10 minutes
   RÃˆGLE 4 - Device Change   : changement device + IP en <1h
   RÃˆGLE 5 - Time Anomaly    : achat 3h-6h du matin (suspect)
   ```

2. **Pipeline Flink**

   - Source : Kafka topic `payments`
   - CEP Pattern Matching (sÃ©quences suspectes)
   - Enrichissement avec PostgreSQL (historique client)
   - Sink : Kafka topic `fraud-alerts` + PostgreSQL table
   - Windowing : sessions 30 min, tumbling 5 min

3. **ModÃ¨le ML supervisÃ©**

   - Features : montant, heure, device, pays, historique
   - Algorithme : XGBoost (classification binaire)
   - Training : 1,583 paiements avec labels (19 fraudes)
   - MÃ©triques : Precision/Recall/F1 (seuil optimal)
   - DÃ©ploiement : MLflow model serving

4. **Dashboards temps rÃ©el**
   - Alertes fraude (temps rÃ©el)
   - Taux de faux positifs/nÃ©gatifs
   - Top rÃ¨gles dÃ©clenchÃ©es
   - Impact financier Ã©vitÃ©

### âœ… Statut actuel : **10% FAIT**

- âœ… 19 paiements frauduleux labellÃ©s en PostgreSQL
- âœ… Table fraud_alerts crÃ©Ã©e
- âŒ Flink pas configurÃ©
- âŒ RÃ¨gles pas implÃ©mentÃ©es
- âŒ ModÃ¨le ML pas entraÃ®nÃ©

### ğŸš€ DÃ©marrage (MVP fraude)

**Objectif** : simuler une dÃ©tection temps rÃ©el avec rÃ¨gles simples et sorties traÃ§ables.

**Plan MVP** :
1. Producer Kafka `payments` depuis `kivendtout_dataset/payments.csv`
2. Consumer `fraud_detector.py` applique les rÃ¨gles
3. Ã‰crit dans PostgreSQL `fraud_alerts`
4. Ã‰met dans Kafka `fraud-alerts`

**Artefacts** :
1. `scripts/fraud/producer_payments.py`
2. `scripts/fraud/fraud_detector.py`
3. `markdowns/FRAUD_MVP.md`


---

## ğŸ—„ï¸ PILIER 4 : DATA LAKE & ANALYTICS - CENTRALISATION & BI

### ğŸ¯ Objectifs mÃ©tier

- **Exigence #3** : Centraliser donnÃ©es brutes (historisation complÃ¨te)
- **Exigence #6** : RÃ©duire temps d'analyse pour BI dÃ©cisionnel

### ğŸ”§ Technologies

- **MinIO** (S3-compatible Data Lake)
- **Apache Parquet** (format columnar optimisÃ©)
- **Apache Superset 3.0** (BI open-source)
- **Apache Airflow 2.8** (orchestration ETL/ELT)
- **dbt** (transformations SQL)

### ğŸ“‹ Livrables

1. **Architecture Data Lake (Medallion)**

   ```
   Bronze Layer (Raw)
   â”œâ”€â”€ /raw/postgres/*.parquet      (dump quotidien)
   â”œâ”€â”€ /raw/mongodb/*.parquet        (events)
   â”œâ”€â”€ /raw/kafka/*.parquet          (stream archives)
   â””â”€â”€ /raw/id_cards/*.png           (images CNI)

   Silver Layer (Cleaned)
   â”œâ”€â”€ /curated/customers.parquet    (dÃ©dupliquÃ©s, validÃ©s)
   â”œâ”€â”€ /curated/orders.parquet       (enrichis)
   â””â”€â”€ /curated/payments.parquet     (normalisÃ©s)

   Gold Layer (Aggregated)
   â”œâ”€â”€ /aggregates/daily_revenue.parquet
   â”œâ”€â”€ /aggregates/top_products.parquet
   â”œâ”€â”€ /aggregates/fraud_stats.parquet
   â””â”€â”€ /aggregates/customer_lifetime_value.parquet
   ```

2. **Pipeline ETL/ELT (Airflow + dbt)**

   - **DAG quotidien** (2h du matin)

     1. Extract : PostgreSQL â†’ Parquet (Bronze)
     2. Extract : MongoDB â†’ Parquet (Bronze)
     3. Transform : dbt models (Bronze â†’ Silver)
     4. Aggregate : dbt models (Silver â†’ Gold)
     5. Test : dbt tests qualitÃ©
     6. Load : Upload MinIO

   - **DAG temps rÃ©el** (micro-batch 15 min)
     1. Kafka â†’ Parquet (incremental)
     2. Append Bronze layer

3. **Dashboards BI (Superset)**

   - **Dashboard ExÃ©cutif**

     - KPI : CA, nb commandes, panier moyen
     - Tendances : croissance hebdo/mensuelle
     - Alertes : chute CA, pic fraudes

   - **Dashboard Fraude**

     - Taux fraude temps rÃ©el
     - CoÃ»t fraude Ã©vitÃ©
     - Top rÃ¨gles dÃ©clenchÃ©es
     - Analyse gÃ©ographique

   - **Dashboard Produits**

     - Top produits/catÃ©gories
     - Stock faible
     - Produits Ã  forte marge

   - **Dashboard Clients**
     - Segmentation RFM (Recency, Frequency, Monetary)
     - Taux rÃ©tention
     - Customer Lifetime Value

### âœ… Statut actuel : **20% FAIT**

- âœ… MinIO installÃ©
- âœ… Parquet files disponibles (dataset)
- âœ… 3 vues SQL PostgreSQL
- âŒ Buckets Bronze/Silver/Gold pas crÃ©Ã©s
- âŒ Airflow pas installÃ©
- âŒ dbt pas configurÃ©
- âŒ Superset pas installÃ©

---

## ğŸ”Œ PILIER 5 : EXPOSITION - API & SERVICES EXTERNES

### ğŸ¯ Objectifs mÃ©tier

- **Exigence #5** : AccÃ¨s simple donnÃ©es via service standardisÃ©
- **Contrainte** : MultiplicitÃ© sources + besoin accÃ¨s externe

### ğŸ”§ Technologies

- **FastAPI 0.109** (framework REST moderne)
- **Swagger/OpenAPI** (documentation auto)
- **JWT** (authentification tokens)
- **Redis** (cache rÃ©ponses)

### ğŸ“‹ Livrables

1. **API RESTful complÃ¨te**

   ```
   # CRUD Clients
   GET    /api/v1/customers
   GET    /api/v1/customers/{id}
   POST   /api/v1/customers
   PUT    /api/v1/customers/{id}
   DELETE /api/v1/customers/{id}

   # Commandes
   GET    /api/v1/orders?status=paid&limit=100
   GET    /api/v1/orders/{id}
   POST   /api/v1/orders

   # Paiements
   GET    /api/v1/payments?is_fraudulent=true
   GET    /api/v1/payments/{id}

   # Fraude
   GET    /api/v1/fraud-alerts
   POST   /api/v1/fraud-alerts/check   (scoring temps rÃ©el)

   # Analytics (cache 5 min)
   GET    /api/v1/analytics/revenue?start_date=2025-01-01
   GET    /api/v1/analytics/top-products?limit=10
   GET    /api/v1/analytics/fraud-rate

   # VÃ©rification identitÃ© (IA)
   POST   /api/v1/verify-identity
          Body: {image: base64, customer_id: "C00001"}
          Response: {is_adult: true, confidence: 0.95, ...}
   ```

2. **Authentification & SÃ©curitÃ©**

   - JWT tokens (expiration 1h)
   - API Keys pour partenaires
   - Rate limiting (100 req/min/user)
   - CORS configurÃ©
   - HTTPS obligatoire (prod)

3. **Documentation interactive**

   - Swagger UI auto-gÃ©nÃ©rÃ©e
   - Exemples requÃªtes/rÃ©ponses
   - Codes erreurs dÃ©taillÃ©s
   - Tutoriels intÃ©gration

4. **Performance**
   - Cache Redis (analytics, top products)
   - Pagination automatique (max 1000 rÃ©sultats)
   - Compression gzip
   - Indexation DB optimale

### âœ… Statut actuel : **0% FAIT**

- âŒ FastAPI pas installÃ©
- âŒ Aucun endpoint crÃ©Ã©
- âŒ Pas de documentation API

---

## ğŸ¤– PILIER 6 : IA & CONFORMITÃ‰ - RECONNAISSANCE CNI

### ğŸ¯ Objectifs mÃ©tier

- **Exigence #11** : ModÃ¨le reconnaissance carte d'identitÃ© pour ventes adultes
- **Contrainte lÃ©gale** : ContrÃ´le automatique documents identitÃ©

### ğŸ”§ Technologies

- **TensorFlow 2.15** (deep learning)
- **OpenCV** (preprocessing images)
- **Tesseract OCR** (extraction texte)
- **MLflow** (versioning modÃ¨les)

### ğŸ“‹ Livrables

1. **Dataset entraÃ®nement**

   - 60 images synthÃ©tiques (PNG 300 DPI)
   - Labels : nom, prÃ©nom, sexe, date naissance, numÃ©ro doc
   - Augmentation : rotation, blur, luminositÃ© (Ã—10 = 600 images)
   - Split : 70% train, 15% validation, 15% test

2. **Pipeline ML**

   ```
   Ã‰tape 1 : Preprocessing
   â”œâ”€â”€ DÃ©tection contours carte (OpenCV)
   â”œâ”€â”€ Redressement perspective
   â”œâ”€â”€ Normalisation taille (800Ã—600)
   â””â”€â”€ Conversion grayscale

   Ã‰tape 2 : Extraction texte (Tesseract OCR)
   â”œâ”€â”€ Zones ROI (nom, prÃ©nom, date naissance)
   â”œâ”€â”€ Correction orthographique
   â””â”€â”€ Validation format dates

   Ã‰tape 3 : VÃ©rification cohÃ©rence
   â”œâ”€â”€ Calcul Ã¢ge depuis date naissance
   â”œâ”€â”€ Validation numÃ©ro document (checksum)
   â”œâ”€â”€ DÃ©tection fraude (photo floue, document expirÃ©)
   â””â”€â”€ Score confiance (0-1)
   ```

3. **ModÃ¨le CNN (architecture)**

   - Input : image 800Ã—600Ã—3
   - Convolution layers : 3Ã—3, 64â†’128â†’256 filters
   - MaxPooling 2Ã—2
   - Dense layers : 512â†’256
   - Output : classification binaire (is_adult)
   - Loss : Binary Cross-Entropy
   - Optimizer : Adam (lr=0.001)

4. **IntÃ©gration production**

   - Endpoint FastAPI `/verify-identity`
   - Upload image (max 5 MB)
   - Temps rÃ©ponse < 2s
   - Logging toutes vÃ©rifications (audit trail)
   - Stockage images MinIO (chiffrÃ©es)

5. **Monitoring modÃ¨le**
   - Accuracy, Precision, Recall (dashboard)
   - Distribution scores confiance
   - Taux faux positifs/nÃ©gatifs
   - Alertes dÃ©gradation performance

### âœ… Statut actuel : **10% FAIT**

- âœ… 60 images + labels disponibles
- âœ… Table identity_verifications crÃ©Ã©e
- âŒ ModÃ¨le TensorFlow pas entraÃ®nÃ©
- âŒ Pipeline preprocessing pas codÃ©
- âŒ API prÃ©diction pas crÃ©Ã©e

---

## ğŸ¯ PILIER TRANSVERSE : SCALABILITÃ‰ & HAUTE DISPONIBILITÃ‰

### ğŸ¯ Objectifs mÃ©tier

- **Exigence #7** : Garantir scalabilitÃ© face Ã  croissance
- **Exigence #8** : Garantir continuitÃ© service (rÃ©silience)

### ğŸ“‹ StratÃ©gies implÃ©mentÃ©es

#### 1ï¸âƒ£ **ScalabilitÃ© horizontale**

- Kafka : 3 brokers (ajout brokers sans downtime)
- Flink : TaskManagers scalables (parallÃ©lisme configurable)
- PostgreSQL : Read replicas (lecture distribuÃ©e)
- MinIO : Distributed mode (multi-nodes)
- FastAPI : Gunicorn multi-workers (auto-scaling)

#### 2ï¸âƒ£ **Haute disponibilitÃ©**

- Kafka replication factor = 3 (tolÃ©rance 2 pannes)
- PostgreSQL streaming replication (failover auto)
- MongoDB replica set 3 nodes (Ã©lection primaire)
- Zookeeper ensemble 3 nodes (quorum)
- Healthchecks Docker (restart automatique)

#### 3ï¸âƒ£ **Monitoring & ObservabilitÃ©**

- **Prometheus** : mÃ©triques infrastructure

  - CPU, RAM, disk, network (node-exporter)
  - MÃ©triques PostgreSQL (postgres-exporter)
  - MÃ©triques Kafka (JMX exporter)
  - MÃ©triques custom (FastAPI)

- **Grafana** : dashboards temps rÃ©el

  - Dashboard infrastructure
  - Dashboard applications
  - Dashboard business (KPI)
  - Alertes (Slack, email)

- **Logs centralisÃ©s** (bonus)
  - ELK Stack : Elasticsearch + Logstash + Kibana
  - Collecte logs Docker containers
  - CorrÃ©lation traces (trace_id)

#### 4ï¸âƒ£ **Disaster Recovery**

- Backup PostgreSQL quotidien (pg_dump)
- Snapshot MinIO hebdomadaire
- Configuration as Code (Git)
- Restore testÃ© mensuellement

### âœ… Statut actuel : **75% FAIT**

- âœ… Kafka 3 brokers HA
- âœ… Prometheus + Grafana installÃ©s
- âœ… Healthchecks Docker
- â³ Backup automatique Ã  configurer
- â³ Logs centralisÃ©s (optionnel)

---

## ğŸ“Š RÃ‰CAPITULATIF - MATRICE PILIERS Ã— EXIGENCES

| Exigence                           | Pilier 1 | Pilier 2 | Pilier 3 | Pilier 4 | Pilier 5 | Pilier 6 | Transverse |
| ---------------------------------- | -------- | -------- | -------- | -------- | -------- | -------- | ---------- |
| **#1** Stockage fiable             | âœ… 100%  | -        | -        | -        | -        | -        | -          |
| **#2** Ã‰vÃ©nements utilisateurs     | -        | â³ 30%   | -        | -        | -        | -        | -          |
| **#3** Data Lake centralisÃ©        | -        | -        | -        | â³ 20%   | -        | -        | -          |
| **#4** DÃ©tection fraude temps rÃ©el | -        | -        | â³ 10%   | -        | -        | -        | -          |
| **#5** API exposition              | -        | -        | -        | -        | âŒ 0%    | -        | -          |
| **#6** BI rapide                   | -        | -        | -        | â³ 25%   | -        | -        | -          |
| **#7** ScalabilitÃ©                 | -        | -        | -        | -        | -        | -        | âœ… 80%     |
| **#8** Haute disponibilitÃ©         | -        | -        | -        | -        | -        | -        | âœ… 75%     |
| **#9** ConformitÃ© sÃ©curitÃ©         | âœ… 70%   | -        | -        | -        | -        | -        | â³ 60%     |
| **#10** QualitÃ© donnÃ©es            | âœ… 60%   | -        | -        | â³ 30%   | -        | -        | -          |
| **#11** IA reconnaissance CNI      | -        | -        | -        | -        | -        | â³ 10%   | -          |

---

## ğŸ—“ï¸ ROADMAP PAR PILIER (7 semaines)

### **Semaine 1-2 : PILIER 2 (Streaming)**

- âœ… Charger events.jsonl â†’ MongoDB
- âœ… CrÃ©er topics Kafka
- âœ… Coder producers/consumers Python
- **Livrable** : 71k Ã©vÃ©nements streamÃ©s en temps rÃ©el

### **Semaine 2-3 : PILIER 3 (Fraude)**

- âœ… Configurer Flink
- âœ… ImplÃ©menter 5 rÃ¨gles dÃ©tection
- âœ… Enrichissement PostgreSQL
- **Livrable** : Alertes fraude temps rÃ©el opÃ©rationnelles

### **Semaine 3-4 : PILIER 5 (API)**

- âœ… Installer FastAPI
- âœ… CrÃ©er 15+ endpoints REST
- âœ… Documentation Swagger
- **Livrable** : API RESTful complÃ¨te et documentÃ©e

### **Semaine 4-5 : PILIER 4 (Data Lake)**

- âœ… CrÃ©er buckets MinIO (Bronze/Silver/Gold)
- âœ… Installer Airflow + dbt
- âœ… DAG ETL quotidien
- **Livrable** : Pipeline ETL/ELT automatisÃ©

### **Semaine 5-6 : PILIER 4 (BI)**

- âœ… Installer Superset
- âœ… CrÃ©er 4 dashboards
- âœ… Alertes automatiques
- **Livrable** : BI dÃ©cisionnel opÃ©rationnel

### **Semaine 6-7 : PILIER 6 (IA)**

- âœ… EntraÃ®ner modÃ¨le TensorFlow
- âœ… API prÃ©diction CNI
- âœ… Tests utilisateurs
- **Livrable** : VÃ©rification identitÃ© automatique

### **Semaine 7 : PILIER 1 & Transverse (Finalisation)**

- âœ… Tests qualitÃ© dbt
- âœ… Backup automatique
- âœ… Logs centralisÃ©s (bonus)
- **Livrable** : Solution production-ready

---

## ğŸ¯ LIVRABLES FINAUX DU PROJET

### ğŸ“¦ **Livrables techniques**

1. Infrastructure Docker Compose (11+ services)
2. Base PostgreSQL (8 tables, 16k+ lignes)
3. Pipeline streaming Kafka + Flink
4. Data Lake MinIO (Bronze/Silver/Gold)
5. API REST FastAPI (20+ endpoints)
6. Dashboards BI Superset (4 dashboards)
7. ModÃ¨le IA TensorFlow (reconnaissance CNI)
8. Pipeline ETL Airflow + dbt
9. Monitoring Prometheus + Grafana
10. Documentation complÃ¨te (30+ pages)

### ğŸ“„ **Livrables documentation**

1. Architecture technique dÃ©taillÃ©e
2. Guide d'installation et dÃ©marrage
3. Documentation API (Swagger)
4. Dictionnaire de donnÃ©es
5. Runbook opÃ©rationnel (troubleshooting)
6. Rapport de tests (unitaires, intÃ©gration, charge)
7. Plan de reprise d'activitÃ© (PRA)
8. Politique RGPD et sÃ©curitÃ©

### ğŸ¬ **Livrables prÃ©sentation**

1. Slides exÃ©cutifs (15 slides max)
2. DÃ©monstration live (15 min)
3. VidÃ©o rÃ©capitulative (5 min)

---

## ğŸ“ˆ INDICATEURS DE SUCCÃˆS (KPI)

| Pilier           | KPI                        | Objectif   | Actuel   |
| ---------------- | -------------------------- | ---------- | -------- |
| **1. Stockage**  | Temps requÃªte moyenne      | <100ms     | âœ… 45ms  |
| **2. Streaming** | Throughput Kafka           | >10k msg/s | â³ 0     |
| **3. Fraude**    | Taux dÃ©tection             | >90%       | â³ 0%    |
| **3. Fraude**    | Faux positifs              | <5%        | â³ N/A   |
| **4. Data Lake** | Taille donnÃ©es             | >100 GB    | â³ 27 MB |
| **4. BI**        | Temps chargement dashboard | <3s        | â³ N/A   |
| **5. API**       | Latence p95                | <200ms     | âŒ N/A   |
| **5. API**       | DisponibilitÃ©              | >99.5%     | âŒ N/A   |
| **6. IA**        | Accuracy CNI               | >95%       | â³ 0%    |
| **Transverse**   | Uptime global              | >99.9%     | âœ… 100%  |

---

## ğŸ“ COMPÃ‰TENCES TECHNIQUES DÃ‰MONTRÃ‰ES

âœ… **Data Engineering**

- ModÃ©lisation relationnelle (PostgreSQL)
- ModÃ©lisation NoSQL (MongoDB)
- Stream processing (Kafka, Flink)
- Batch processing (Airflow, dbt)
- Data Lake architecture (MinIO, Parquet)

âœ… **DevOps & Infrastructure**

- Containerisation (Docker Compose)
- Orchestration (Kubernetes bonus)
- Monitoring (Prometheus, Grafana)
- CI/CD (Git, GitHub Actions bonus)

âœ… **Data Science & IA**

- Machine Learning (fraude)
- Deep Learning (CNN, TensorFlow)
- Computer Vision (OCR)
- MLOps (MLflow, versioning)

âœ… **Backend Development**

- API REST (FastAPI, Swagger)
- Authentification (JWT)
- Performance (cache, indexation)

âœ… **Business Intelligence**

- Dashboards (Superset)
- MÃ©triques business (KPI)
- Data visualization

---

**ğŸ“… Date de livraison prÃ©vue** : 24 mars 2026 (7 semaines)  
**ğŸ‘¤ Responsable projet** : Pierre Chevalier & Jean Macario
**ğŸ¯ Score objectif** : 105/110 points (96%)
